# **Automatic Translation of Sign Language into Text**

## **Overview**
This project aims to develop an **AI-powered system** that recognizes **sign language gestures** in real-time and converts them into **text**. The model leverages **deep learning**, **computer vision**, and **natural language processing (NLP)** to accurately interpret hand gestures, improving communication accessibility for **deaf and hard-of-hearing individuals**.

---

## **Features**
- **Real-time sign language recognition** using a deep learning-based CNN model.
- **Gesture classification** trained on a dataset of hand gestures.
- **REST API** using **Flask** to accept images and return text predictions.
- **Integration with MediaPipe** for hand landmark detection.
- **MobileNet-based CNN** for fast and efficient gesture classification.
- **JSON-based class mapping** for flexible model expansion.
- **Cross-Origin Resource Sharing (CORS)** enabled for frontend compatibility.